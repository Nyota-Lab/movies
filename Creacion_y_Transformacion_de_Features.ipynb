{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Creacion y Transformacion de Features.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nyota-Lab/movies/blob/Features/Creacion_y_Transformacion_de_Features.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCUrziNwkn8t",
        "colab_type": "text"
      },
      "source": [
        "#Creacion y Transformacion de Features\n",
        "* Dado que nuestro problema de rendimiento no viene condicionado por la falta de features, es necesario crear nuevas o transformar las existentes\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yU8VVDYhke4-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GMDnBv8lwXo",
        "colab_type": "text"
      },
      "source": [
        "##Reescalamiento de los datos\n",
        "* Es recomendable reescalar los datos para poder tenerlos de una forma mas compacta LAS REGRESIONES NO SE VEN AFECTADAS POR EL REESCALAMIENTO LAS CLASIFICACIONES SI LO SON, existen dos formas de hacer este reescalamiento de los datos:\n",
        " * Llevarlo a cero haciendo una resta del promedio de los valores que tienen las features\n",
        " * Dividirlo por su desviacion estandar"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBoi8ni0mTvB",
        "colab_type": "code",
        "outputId": "7c1647d9-c948-4c27-b7a1-604cfb9bd908",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CT5vxOZ3mq_j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#X = pd.read_csv(r'C:\\Users\\willi\\Documents\\Programacion\\ML\\x.csv')\n",
        "path = ('/content/drive/My Drive/Peliculas/X.csv')\n",
        "X = pd.read_csv('/content/drive/My Drive/Peliculas/X.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvyVQho1m5a0",
        "colab_type": "text"
      },
      "source": [
        "* Como siempre volvemos a generar los conjuntos de Test y Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bN2qB6Cke5T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = X['worldwide_gross']\n",
        "X = X.drop(['worldwide_gross','gross'], axis=1)\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUb5pBV3nXzw",
        "colab_type": "text"
      },
      "source": [
        "* Usamos preprocessing para calcular la desviacion estandar y lo instanciamos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFDdrySEke5i",
        "colab_type": "code",
        "outputId": "d7c7f01e-117b-4b6c-eeae-41adc9df7ec9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StandardScaler(copy=True, with_mean=True, with_std=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RjNp2Qjgsobr",
        "colab_type": "text"
      },
      "source": [
        "* scaler tiene algunos métodos pero dentro de estos podemos calcular la media y la desviacion estandar de cada uno de los features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aN5iy-pDke5x",
        "colab_type": "code",
        "outputId": "b37c6662-bf7f-4f38-f4b2-f7b108cccb00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "scaler.mean_"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3.32173071e+07, 2.00216971e+03, 2.12130186e+00, 1.08690771e+02,\n",
              "       1.00827008e+04, 3.73667960e+07, 6.44580897e+00])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "5riCdXYnke6J",
        "colab_type": "code",
        "outputId": "b2e801e3-305a-4c37-dc5e-68a28d31545f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "scaler.scale_"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4.05797687e+07, 1.19323638e+01, 6.74618060e-01, 2.32546381e+01,\n",
              "       1.81442411e+04, 6.68555370e+07, 1.07899204e+00])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7nf6UDLtBzr",
        "colab_type": "text"
      },
      "source": [
        "* Observemos que actualmente los valores están en diferentes escalas y tiene muchas diferencias entre si"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcC1_Bu8ke6V",
        "colab_type": "code",
        "outputId": "945faf69-c0ef-40f7-87cb-36a95fe917d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        }
      },
      "source": [
        "X_train.values"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.5000000e+08, 2.0120000e+03, 1.8500000e+00, ..., 1.6184000e+04,\n",
              "        1.5000000e+08, 5.8000000e+00],\n",
              "       [7.1682975e+07, 2.0040000e+03, 1.8500000e+00, ..., 7.2730000e+03,\n",
              "        6.0000000e+07, 6.5000000e+00],\n",
              "       [2.3000000e+07, 1.9870000e+03, 2.3500000e+00, ..., 2.3550000e+03,\n",
              "        2.3000000e+07, 2.8000000e+00],\n",
              "       ...,\n",
              "       [3.5000000e+07, 2.0060000e+03, 1.8500000e+00, ..., 2.4640000e+04,\n",
              "        3.5000000e+07, 7.3000000e+00],\n",
              "       [3.0000000e+07, 2.0040000e+03, 1.8500000e+00, ..., 2.0097000e+04,\n",
              "        3.0000000e+07, 7.0000000e+00],\n",
              "       [1.8000000e+07, 2.0050000e+03, 1.8500000e+00, ..., 1.6150000e+03,\n",
              "        1.7000000e+07, 6.3000000e+00]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOZne0oQtO6c",
        "colab_type": "text"
      },
      "source": [
        "* scaler tiene otro metofo que es transform el cual nos va a permitir realizar el escalamiento de los datos\n",
        "* Observamos que nuestros datos ya pasan de estar en una escala muy diferente a encontrarse en valores decimales o muy cercanos a cero y entre sí"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YE_M_w0xke6g",
        "colab_type": "code",
        "outputId": "875cbb00-82ef-4b55-bd9d-2a4518b5e1a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        }
      },
      "source": [
        "scaler.transform(X_train)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 2.87785507,  0.82383464, -0.40215624, ...,  0.33626643,\n",
              "         1.68472514, -0.59852987],\n",
              "       [ 0.94790259,  0.1533891 , -0.40215624, ..., -0.15485358,\n",
              "         0.33853896,  0.05022376],\n",
              "       [-0.25178328, -1.27130765,  0.33900387, ..., -0.42590377,\n",
              "        -0.21489314, -3.37890256],\n",
              "       ...,\n",
              "       [ 0.04393058,  0.32100049, -0.40215624, ...,  0.80230962,\n",
              "        -0.03540165,  0.79165647],\n",
              "       [-0.07928352,  0.1533891 , -0.40215624, ...,  0.55192715,\n",
              "        -0.11018977,  0.5136192 ],\n",
              "       [-0.37499738,  0.2371948 , -0.40215624, ..., -0.46668806,\n",
              "        -0.30463888, -0.13513442]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-n_mIKQHvtoz",
        "colab_type": "text"
      },
      "source": [
        "* Tenemos quue tener en cuenta que tanto los datos de train como los de test deben estar escalados con el mismo scaler\n",
        "vamos a crear dos nuevos grupos de datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPVT3CSBke6n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_scaled, X_test_scaled = (scaler.transform(X_train), scaler.transform(X_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QiPhS9QJwEwt",
        "colab_type": "text"
      },
      "source": [
        "* Una vez tenemos nuestros datos normales y escalados es hora de probar si existe una mejora en el rendimiento de nuestro modelo Lasso"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4LmCDfTjke60",
        "colab_type": "code",
        "outputId": "e6714f0b-4660-42d3-895c-126dcd3e0d52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "from sklearn.linear_model import Lasso\n",
        "model = Lasso()\n",
        "model_scaled = Lasso()\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "model_scaled.fit(X_train_scaled, y_train)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
              "      normalize=False, positive=False, precompute=False, random_state=None,\n",
              "      selection='cyclic', tol=0.0001, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2jv7eA7ke6-",
        "colab_type": "code",
        "outputId": "10aa8a99-870d-4b5d-8f0d-c20154db720c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(model.score(X_test, y_test))\n",
        "print(model_scaled.score(X_test_scaled, y_test))"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.582437977847351\n",
            "0.5824379819402636\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QpJM3W2Ew9Gr",
        "colab_type": "text"
      },
      "source": [
        "* Como explicamos al principio el reescalamiento puede generar mejoras en el rendimiento de algunos modelos pero en las regresiones especificamente no tiene un impacto siginificativo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTK1XB3QyB7W",
        "colab_type": "text"
      },
      "source": [
        "##Pipelines\n",
        "\n",
        "* Podemos simplificar las transformaciones con pipelines de esta manera el podemos unir algunos de los pasos previos para realizar la estandarizacion esto resulta en un codigo mucho mas replicable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2G6KPV8ke7J",
        "colab_type": "code",
        "outputId": "887b059a-349d-4431-d867-388b3af3f7aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "from sklearn.pipeline import make_pipeline\n",
        "model_scaled = make_pipeline(StandardScaler(),\n",
        "                            Lasso())\n",
        "model_scaled.fit(X_train, y_train)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('standardscaler',\n",
              "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
              "                ('lasso',\n",
              "                 Lasso(alpha=1.0, copy_X=True, fit_intercept=True,\n",
              "                       max_iter=1000, normalize=False, positive=False,\n",
              "                       precompute=False, random_state=None, selection='cyclic',\n",
              "                       tol=0.0001, warm_start=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7tnWO5syn8D",
        "colab_type": "text"
      },
      "source": [
        "* Comprobamos que nuestro pipeline funcione correctamente"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KldTl6Uke7X",
        "colab_type": "code",
        "outputId": "8cf4cf1c-c65a-47f3-b212-978e5909ea13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "print(model_scaled.score(X_test, y_test))"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5824379819402636\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wQTK3CNy6ym",
        "colab_type": "text"
      },
      "source": [
        "##Creación de Features de forma automática\n",
        "* sklearn tambien nos ofrece una forma de crear nuevas features a partir de las que tenemos de forma automática\n",
        "* Para entender como funciona vamos a crear una matriz y le aplicaremos la creación de features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-cQgDXLke7i",
        "colab_type": "code",
        "outputId": "b2c5c71d-4ff3-4306-fa9d-94188aafdec8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "A = np.arange(6).reshape(3, 2)\n",
        "A"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 1],\n",
              "       [2, 3],\n",
              "       [4, 5]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4EQUKsAAz8_4",
        "colab_type": "text"
      },
      "source": [
        "* Importamos PolynomialFeatures y lo instanciamos\n",
        "* Este metodo tiene un parámetro que es el grado de los polinomios"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DitxAzXIke7q",
        "colab_type": "code",
        "outputId": "86f07267-373f-4a68-8d8f-bc228b7b1f27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "transformer = PolynomialFeatures(2)\n",
        "#regularmente el metodo trasnform se usa solo una vez, para evitar escribir lineas de código\n",
        "#podemos usarlo de la siguiente manera\n",
        "transformer.fit_transform(A)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.,  0.,  1.,  0.,  0.,  1.],\n",
              "       [ 1.,  2.,  3.,  4.,  6.,  9.],\n",
              "       [ 1.,  4.,  5., 16., 20., 25.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVLm7VugiCWl",
        "colab_type": "text"
      },
      "source": [
        "* Ahora vamos a aplicar la creacion de features para nuestro dataframe en particular, vemos que hasta el momento tenemos 7"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "kEzw90nKke71",
        "colab_type": "code",
        "outputId": "03546849-30c4-4314-eef7-a69890702395",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "X.shape"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4104, 7)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jw--CYyRiQzk",
        "colab_type": "text"
      },
      "source": [
        "* Aplicamos el método transformer\n",
        "* Este transformador genera las combinaciones posibles entre features entre mas features iniciales tengamos, mas se van a generar con el metodo transform"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_YAY54Bke78",
        "colab_type": "code",
        "outputId": "24a12599-2f9c-4365-9f3e-2ca8e88cfe32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "transformer = PolynomialFeatures(2)\n",
        "X4 = transformer.fit_transform(X)\n",
        "print(X4.shape)\n",
        "from sklearn.model_selection import train_test_split\n",
        "X4_train, X4_test, y4_train, y4_test = train_test_split(X4,y)\n",
        "print(X4_train.shape)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4104, 36)\n",
            "(3078, 36)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3euRXq_i7N3",
        "colab_type": "text"
      },
      "source": [
        "* Vamos a entrenar nuestro modelo con las nuevas features\n",
        "* Verificamos que nuestro rendimiento baja mucho, esto se debe a que aumentamos demasiadas features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ev1AR-rGjBa4",
        "colab_type": "code",
        "outputId": "5ec20eff-762b-408a-e7d6-2a4e96d6d6b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 93
        }
      },
      "source": [
        "model_poly = Lasso()\n",
        "model_poly.fit(X4_train,y4_train)\n",
        "model_poly.score(X4_test,y4_test)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.6922630498782069e+19, tolerance: 9790433278244940.0\n",
            "  positive)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.348316754699998"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BlLp4tDlikM",
        "colab_type": "code",
        "outputId": "2db844f8-8c89-4a82-d58c-895b19e5a5d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "X4_train.shape"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3078, 36)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCZqdyFVo7Xt",
        "colab_type": "text"
      },
      "source": [
        "##Creacion a partir de variables categoricas (One Hot Encoding)\n",
        "* Es posible crear features de orden categórica con el fin de poder hacer un análisis de las mismas\n",
        "asignar un numero a cada valor en un orden (1,2,3,4,...) es que la distancia entre ellos puede afectar el rendimiento\n",
        "en este caso se usa un Encoding one-hot, el cual crea columnas y las rellena con 1 y 0 dependiendo del valor\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQynZXCmke8E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = ('/content/drive/My Drive/Peliculas/movies_obj.csv')\n",
        "movies_obj = pd.read_csv('/content/drive/My Drive/Peliculas/movies_obj.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oEi4KQbtqR1N",
        "colab_type": "text"
      },
      "source": [
        "* Primero miramos la cantidad de valores unicos que tiene cada una de las features, nunique nos ayuda a contar los valores unicos y sort_values()los ordena \n",
        "* Hay que tener en cuenta que se puede aumentar demasiadas features utilizando éste método\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4jpXcF3ke8L",
        "colab_type": "code",
        "outputId": "a521c6f0-81ab-4584-99da-be016056b7a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "movies_obj.apply(pd.Series.nunique).sort_values()"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "color                2\n",
              "content_rating      18\n",
              "language            47\n",
              "country             65\n",
              "genres             914\n",
              "actor_1_name      2097\n",
              "director_name     2398\n",
              "actor_2_name      3032\n",
              "actor_3_name      3521\n",
              "plot_keywords     4760\n",
              "movie_title       4917\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "joDhZgJzr3vY",
        "colab_type": "text"
      },
      "source": [
        "##Encoding Binario\n",
        "* Otra opcion es hacer un encoding binario es decir convertir la categoría en un número este numero se convierte en un binario y creamos columnas de acuerdo al mayor numero\n",
        "* Este al no ser un metodo propio de sklearn es necesario cargar otra libreria"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuZSNXkoke8T",
        "colab_type": "code",
        "outputId": "d9b54e41-699b-442e-ea48-f2b5e4ae1867",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        }
      },
      "source": [
        "!pip install category_encoders"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting category_encoders\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a0/52/c54191ad3782de633ea3d6ee3bb2837bda0cf3bc97644bb6375cf14150a0/category_encoders-2.1.0-py2.py3-none-any.whl (100kB)\n",
            "\r\u001b[K     |███▎                            | 10kB 8.8MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 20kB 4.1MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 30kB 5.2MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 40kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 51kB 3.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 61kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 71kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 81kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 92kB 5.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 102kB 4.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.18.2)\n",
            "Requirement already satisfied: statsmodels>=0.6.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.10.2)\n",
            "Requirement already satisfied: pandas>=0.21.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.25.3)\n",
            "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.4.1)\n",
            "Requirement already satisfied: patsy>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.5.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.22.2.post1)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category_encoders) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category_encoders) (2018.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from patsy>=0.4.1->category_encoders) (1.12.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20.0->category_encoders) (0.14.1)\n",
            "Installing collected packages: category-encoders\n",
            "Successfully installed category-encoders-2.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79RYYDY_tjj4",
        "colab_type": "text"
      },
      "source": [
        "* Tenemos un dataframe con solo 2 columnas que son las cuales nos van a servir para esta transformacion y lo cargamos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QdAZYiRRke8d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path =('/content/drive/My Drive/Peliculas/categoricals.csv')\n",
        "categoricals = pd.read_csv('/content/drive/My Drive/Peliculas/categoricals.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPYYAE6Vtyfz",
        "colab_type": "text"
      },
      "source": [
        "* Conocemos que existen algunos valores faltantes en nuestro dataframe por lo que vamos a reemplazarlos por 0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "logiLoXrke8l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "categoricals = categoricals.reset_index(drop=True).fillna(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3PT48MjxMPR",
        "colab_type": "text"
      },
      "source": [
        "* Una cez arreglamos los datos faltantes en nuestro dataframe concatenamos los dos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-j1uWigke8t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_binenc = pd.concat((X,categoricals),axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkg03zPyxtPA",
        "colab_type": "text"
      },
      "source": [
        "* Importamos category_encoders e instanciamos el mismo usando BinaryEncoder y seleccionando las columnas a usar"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2WqlVjkke81",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import category_encoders as ce\n",
        "encoder = ce.BinaryEncoder(cols=['actor_1_name','director_name'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLpzN5wGke86",
        "colab_type": "code",
        "outputId": "b3f4bebb-05fc-4b0a-a43f-c76e81f7ede1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "X_binenc = encoder.fit_transform(X_binenc)\n",
        "print(X_binenc.shape)\n",
        "print(y.shape)"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4104, 32)\n",
            "(4104,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dy1nxPPNyc_J",
        "colab_type": "text"
      },
      "source": [
        "* Ahora generamos nuestros conjuntos de prueba y entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhDI6ktDke9E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Xb_train, Xb_test, y_train, y_test = train_test_split(X_binenc,y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcJWra9b6Fb2",
        "colab_type": "text"
      },
      "source": [
        "* Vamos a generar tambien unos conjuntos de comprobancion para ver la diferencia en el rendimiento de los dos dataframes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jot-T7LRke9M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test = (Xb_train[X.columns], Xb_test[X.columns])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jdVwa2e6O6Q",
        "colab_type": "text"
      },
      "source": [
        "* Entrenamos los modelos con el binary_encoding y el de control"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXyip2Tuke9T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_binenc = Lasso()\n",
        "model = Lasso()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyLbRJQr7LqK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "56c39060-4885-4329-87f1-af4c3d717add"
      },
      "source": [
        "model_binenc.fit(Xb_train,y_train)\n",
        "model.fit(X_train,y_train)"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
              "      normalize=False, positive=False, precompute=False, random_state=None,\n",
              "      selection='cyclic', tol=0.0001, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxqkRA4v6gXS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "67fbab32-5fa3-42c3-ab22-52ef0756aadd"
      },
      "source": [
        "print(model_binenc.score(Xb_train,y_train))\n",
        "print(model.score(X_train,y_train))"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5827002282133342\n",
            "0.5705199150894189\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}